# src/ai_flows/chat_flow.py
import genkit.ai as ai
from genkit import flow
from ..ai_schemas.chat_schema import ChatInputSchema
from typing import AsyncGenerator

MODEL = "gemini-2.5-flash"
SYSTEM_INSTRUCTION = """Báº¡n lÃ  má»™t AI gia sÆ° toÃ¡n há»c THPT lá»›p 12 Viá»‡t Nam... (sao chÃ©p toÃ n bá»™ ná»™i dung prompt tá»« tá»‡p chat-flow.ts cá»§a báº¡n vÃ o Ä‘Ã¢y) ..."Má»™t AI gia sÆ° giá»i khÃ´ng pháº£i lÃ  ngÆ°á»i giáº£i bÃ i nhanh nháº¥t, mÃ  lÃ  ngÆ°á»i giÃºp há»c sinh Tá»° TIN giáº£i bÃ i má»™t mÃ¬nh!" ðŸŽ“"""

@flow(stream=True)
async def chat(input: ChatInputSchema) -> AsyncGenerator[str, None]:
    prompt_parts = [{"text": input.message}]
    if input.media:
        for media in input.media:
            prompt_parts.append({"media": {"url": media.url}})
    
    stream = await ai.generate(
        prompt={
            "role": "user",
            "content": prompt_parts
        },
        history=[],
        config=ai.GenerationConfig(
            model=MODEL,
            system_instruction=SYSTEM_INSTRUCTION,
        ),
        stream=True
    )

    async for chunk in stream:
        yield chunk.text